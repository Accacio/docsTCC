
\chapter{Background}
\label{cha:background}
This chapter will discuss the main topics needed to understand this work, from
discrete event systems to discrete control implementation on \PLCs, a more
detailed explanation of each topic can be found on the respective cited work.
\section{Systems}

A System as defined by the Cambridge's dictionary is ``a set of connected things
or devices that operate together''. As seen two basic properties of systems are
:
\begin{itemize}
\item they are formed by grouping smaller parts
\item the smaller parts when grouped work together to carry out a specific
  function
\end{itemize}

As its definition is so abstract almost anything can be defined as a system,
physical or not, beings can be defined as systems and even economic mechanisms
can also be considered as systems.

Usually systems are modelled by a Input\slash Output process. The system is fed with a
set of inputs, it process the inputs resulting on the output set, as we can see
in \autoref{fig:ioProcModel}.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    % \node[anchor=south west,inner sep=0] (image) at (0,0) {
    %   \includegraphics[trim={0 0 0 0},clip,width=8cm]{maquete/sensores/69511_3.jpg}
    % };
    % \draw[red,ultra thick,rounded corners] (0,0) rectangle (9.4,6.2);
    % \begin{scope}[x={(image.south east)},y={(image.north west)}]
        \draw[ultra thick,rounded corners] (3.5,4) rectangle (6.5,6);
        \draw (5,5) node {\textbf{Process}};
        \draw (0,5) node {\textbf{Inputs}};
        \draw[->,>=stealth, very thick] (1,4.5) -- ++ (2.5,0);
        \draw[->,>=stealth, very thick] (1,5)   -- ++ (2.5,0);
        \draw[->,>=stealth, very thick] (1,5.5) -- ++ (2.5,0);
        \draw (10,5) node {\textbf{Outputs}};
        \draw[->,>=stealth, very thick] (6.5,4.5) -- ++ (2.5,0);
        \draw[->,>=stealth, very thick] (6.5,5)   -- ++ (2.5,0);
        \draw[->,>=stealth, very thick] (6.5,5.5) -- ++ (2.5,0);
      % \end{scope}
    \end{tikzpicture}
  \caption{Input\slash Output Process model}
    \label{fig:ioProcModel}
\end{figure}


In some systems, its inputs and outputs can't represent it's behaviour, so the
concept of state is created, and it represents the behaviour of the system in a
given instant $t$.

The states can be continuous or discrete, and the systems which these states
represent can be considered as Continuous Systems, Discrete Systems or even
Hybrid Systems, which combine both kind of states.

The systems modelled in this work are Discrete Systems, more details about other
kinds of systems as well as examples and their analysis can be found on
\cite{oppenheim1996signals} and \cite{kalouptsidis1997signal}.
\section{Discrete Event Systems}
\label{sec:discreteEventSystems}
Discrete Systems can be driven by time and by events. It means, the states can
be changed continuously by the time or instantaneously by some ensemble of events.

In this thesis we are interested in the event-driven type. Some basic mathematical
formalisms, nomenclature and representations can be developed to facilitate the
understanding. Some of those will be presented in the following sections based
on \cite{cassandras2009introduction, david2005discrete,david1989grafcet}.
\section{Languages} \label{sec:automata} A language can be defined by the Merriam-Webster's dictionary as ``a systematic
means of communicating ideas or feelings by the use of conventionalized signs,
sounds, gestures, or marks having understood meanings'' And as it is defined by
this dictionary entry we pursue to communicate the complete behaviour of the
\DES. Firstly we need to define a group, or set of marks to characterise the
singular behaviour of the system. So, we define a set $\Sigma$. This set contains
all elements which combined can create a language. Again in analogy with
linguistics, each one of these marks, the events can be compared to letters ,
provided that $\Sigma$ can be called an ``alphabet'', and the combination of its
events ``words''. Words are also called ``strings '' or even ``traces''.
Considering the use of the word ``string'' as the variable type used on several
programming languages used in this work, we prefer the use of the vocables
``word'' and ``trace''. We can also define a mark to represent an empty word,
$\epsilon$, that is, a word that is not formed by any event.

The combination process to form words is called concatenation. For instance,
given two events $a$ and $b$, the words $ab$ and $ba$ can be created concatenating these two events and there is no particular reason to suppose that $ab$ is equal to $ba$, the same way the words ``ten'' and ``net'' have different meanings in English.

We can also concatenate two words, to create a different one, we can take the
words $ab$ and $ba$ and create words like $abba$ and $baab$.

As we extended the definition of concatenation to words, we define $\epsilon$,
the empty word, as the identity element of concatenation: $w\epsilon = \epsilon
w = w$ for any word $w$.

Likewise, we can define the length of a word as the number of events contained
by this word, we denote the length with two vertical bars, given a word $w$ its
length is equal to $|w|$ and by definition $|\epsilon| = 0 $.

As we know, there is a great number of human western languages, as portuguese,
english, french, spanish etc, that roughly are formed by the same alphabet, but
overall they are formed by different combination of words. Similar things can
happen with languages that define the \DESs, so we can define as in
\cite{cassandras2009introduction}.
% \pagebreak
\begin{definition}[Language]
  \label{def:language}~\\
  A Language defined over an alphabet $\Sigma$ is formed from finite-length
  words generated from the concatenation of the events in $\Sigma$ and
  $\epsilon$.
\end{definition}

Take for example an alphabet $\Sigma = \{a,b,g\}$, we can define different
languages
\begin{subequations}
  \begin{equation*}
  L_1=\{\epsilon, a, abb\}
  \end{equation*}
  \begin{equation*}
  L_2=\{\text{all possible words of length 3 starting with g}\}
  \end{equation*}
  \begin{equation*}
  L_3=\{\text{all possible words starting with g}\}
  \end{equation*}
\end{subequations}

The cardinality of this sets are $|L_1|=3$, $|L_2|=9$, $|L_3|=\infty$
As we can see from the same alphabet very different languages can be created, thus we can define a way to encapsulate all possible languages generated from
the same alphabet $\Sigma$. Let us denote by $\Sigma^*$ the set containing all
finite words composed with the elements of $\Sigma$ and $\epsilon$. The *
operation is called the \textit{Kleene-closure}. Similarly to $L_3$ it is
countably infinite since it contains arbitrarily long words. For instance the
\textit{Kleene-closure} of the alphabet $\Sigma = \{a, b, c\}$ is:
\begin{equation*}
  \label{eq:kleeneExample}
  \Sigma^* = \{\epsilon,a,b,c,aa,ab,ac,ba,bb,bc,ca,cb,cc,aaa,\dots\} 
\end{equation*}
There are a few operations with languages and alphabets that can be defined, but they are outside the scope of this work, they can be found on \cite{cassandras2009introduction}.
\section{Representation of Languages}
\label{sec:representationLanguages}

Although languages can describe the behaviour of \DESs, there are cases, as the
one shown
by the language $L_3$ in the last section, in which the language is enormous, in
that case countably infinite, what makes them not so simple to communicate the
behaviour of the system. For this purpose, there are some other formalisms that
aid the comprehension, since they can be a more compact way of expressing the
system's behaviour or accompanied by diagrams.

In the following subsections two of the most known representations will be
presented: Automata and Petri Nets.

% \pagebreak
\subsection{Automata}
\label{sec:automata}
One of the most known representation of languages are automata. The notion of
automaton is basically the definition of \DESs, as we saw in the
\autoref{sec:discreteEventSystems}: a set of events can change the state of the
system. If we know all the events composing the language of the
system and its states, we can have its alphabet $\Sigma$ and we can create a set $X$ composed
by all states.
From $\Sigma$ and $X$ we can derive a function that represents the transition
from a state to other, this function is called \emph{transition function} of the automaton
denoted as $f : X \times \Sigma \rightarrow X$. For example if a system have an
alphabet $\Sigma = \{a,b\}$ and 2 states, we can name the states $x$ and
$y$, and then create the set $X = \{x,y\}$. Knowing that the system begins at state $x$
and that when event $a$ happens it changes to state $z$ we can create a function
$f(x,a)$ and define it as $y$. Likewise if we know that when the system is at
state $y$ and event $b$ happens, a function $f(y,b)$ can be defined as $a$.

As a
visual aid, a representation of these functions can be made through a diagram, called \emph{state transition diagram}. In this kind of diagram the states are
represented by circles labeled with their names, and the functions as arcs
labeled with the corresponding event,connecting two states, with arrows in one of their
extremities indicating the transition from a state to other. The initial state
of the automaton has an arc pointing towards it coming from no other state.
\autoref{fig:functionDiagram} can represent the functions $f(x,a)$ and $f(y,b)$
described in the last paragraph.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.3\textwidth]{automata/function/function.tikz}
  \caption{State Transition Diagram}
  \label{fig:functionDiagram}
\end{figure}
Now, for a more complex example, from \cite{cassandras2009introduction}:

\begin{example}[Simple Automaton] ~\\
  \label{ex:simpleAutomaton}
  Given $\Sigma = \{a,b,g\}$, $X = \{x,y,z\}$ and the following transition functions:
  \begin{align*}
   f(x,a)&=x&f(x,g)&=z\\
   f(y,a)&=x&f(y,b)&=y\\
   f(z,b)&=z&f(z,a)&=f(z,g)=y\\
 \end{align*}
\end{example}
We can represent this automaton with the diagram on \autoref{fig:diagramExapleAutomata}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{automata/example/example.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Diagram representing the automaton from example \ref{ex:simpleAutomaton}}
  \label{fig:diagramExapleAutomata}
\end{figure}
We can also mark states that have some special meaning, a final state for instance. In this work, as in \cite{cassandras2009introduction} they are
  going to be identified by double circles.

  
  Now a deterministic Automaton can be defined:
\begin{definition}[Deterministic Automaton]
  \label{def:DeterministicAutomaton}~\\
  A Deterministic Automaton, denoted by G, is a five-tuple
  \[ G = (X,\Sigma,f, x_0,X_m)\] where:

  \indent X is the set of \textbf{states} \\
  \indent $\Sigma$ is the finite set of \textbf{events} associated with G\\
  \indent $f: X \times \Sigma \rightarrow X$ is the \textbf{transition function}  \\
  \indent $x_0$ is the \textbf{initial state} \\
  \indent $X_m \subseteq X $ is the set of \textbf{marked states}

\end{definition}


Other kinds of automata and operations between automata exist but are not going
to be used in this work, again \cite{cassandras2009introduction} present them.

\subsection{Petri Nets}
\label{sec:petriNets}
Another kind of representation of languages are Petri Nets, whose concept was created by C.A.Petri
in the early 1960's. Differently from the automata representation that are
basically formed from states, Petri nets are bipartite graphs, formed by nodes
called \emph{places} and \emph{transitions}.
Transitions represent the events that drive the system, and places represent the
conditions for these events to happen. The mechanism to represent the fulfilment
of the conditions
is named marking. A petri net is built over three basic concepts, the petri net
graph\slash structure, its marking and firing transitions.
The next subsections will be based on \cite{david2005discrete} and \cite{cassandras2009introduction}.

\subsubsection{Petri Net Graph}
\label{sec:petrinetGraph}
Similarly, arcs are used to connect
the nodes and have arrowheads to identify the direction,
but differently, all arcs must have exclusively one node at each end, that means
no arc is used to identify the initial state of a petri net. As said, a petri net is
bipartite graph, that means places can only connect to transitions and vice
versa. In this work as in \cite{david2005discrete} places will be represented by
circles and transitions by bars. 
\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{0.45\textwidth}
  \centering
  \includegraphics{petriNet/net/place.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{A place.}
\end{subfigure}
~
\begin{subfigure}[t]{0.5\textwidth}
  \centering
  \includegraphics{petriNet/net/transition.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{A transition}
\end{subfigure}
  \caption{Component nodes of a petri net.}  
\end{figure}

The same way a function was created to define the transitions of states in an
automaton, two functions will be created to define the connections between places
and transitions. First we need to define the sets of places and transitions. $P$
is the set of places and $T$ the set of transitions. With this two sets we can
then define those functions. The first one represents the arcs
from places to transitions, and is denoted as $Pre: P \times T \rightarrow
\{0, 1\}$, the second one the arcs that connects transitions to places, denoted
as $Post: P \times T \rightarrow \{0,1\}$. The value $1$ is attributed to arcs
that exist and $0$ to the nonexistent ones.


\begin{example}[Simple Petri Net structure] ~\\
  \label{ex:simplePetriNetStructure}
  Given $P = \{p_0,p_1\}$, $T = \{t_0,t_1,t_2\}$ and the following transition
  functions:
  \begin{align*}
   Pre(p_0,t_0)& = 0  &  Post(p_0,t_1) &= 0 & Pre(p_1,t_0) &= 0 &  Post(p_1,t_1) &= 1 \\
   Post(p_0,t_0) &= 0  &    Pre(p_0,t_2) &= 0   & Post(p_1,t_0) &= 0   & Pre(p_1,t_2) &= 0\\
   Pre(p_0,t_1) &= 0    &  Post(p_0,t_2) &= 0  &  Pre(p_1,t_1) &= 0     &Post(p_1,t_2) &= 0\\
  \end{align*}
  We can represent this petri net structure with the diagram on \autoref{fig:simplePetriNetStructure}
\end{example}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{petriNet/prepost/prepost.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Diagram representing the petri net structure from example \ref{ex:simplePetriNetStructure}}
\label{fig:simplePetriNetStructure}
\end{figure}
A drawback from the definition of this functions, is that is not possible to
have more than an arc linking two nodes, so we can generalize them to any natural number:
\begin{align*}
  Pre:  P \times T \rightarrow \mathbb{N}_0\\
  Post: P \times T \rightarrow \mathbb{N}_0
\end{align*}
with this new definition we can change the definition of $Post(p_1,t_1)$ from
$0$ to $2$ resulting on the following petri net structure.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{petriNet/prepost/prepost2.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Diagram representing the petri net structure from example
    \ref{ex:simplePetriNetStructure}, but with $Post(p_1,t_1)=2$}
\label{fig:simplePetriNetStructureNatural}
\end{figure}
In order to reduce the number of arcs in a diagram, usually only one arc is
drawn and a label is added with the value of its respective function, if it is
greater than $1$, \autoref{fig:simplePetriNetStructureGeneralized} illustrates it:
\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{petriNet/prepost/prepost3.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Same diagram as \autoref{fig:simplePetriNetStructureNatural} but with
    labeled arcs.}
\label{fig:simplePetriNetStructureGeneralized}
\end{figure}

\subsubsection{Marking}
\label{sec:marking}

As said in the beginning of this subsection marking is used as the mechanism to
represent if the condition of occurrence of a determined event is met or not.
But also it can be used to represent the state of the system. The mechanism
works as follows. Tokens can be designated to places and the way the tokens are
distributed among places is called the marking of a petri net graph. We can define a marking function $x :
P \rightarrow \mathbb{N}$ that denotes the number of tokens in a determined place.
In this
work, as in the majority of articles and books, the tokens will be
represented as black dots inside the places. 

The
\Autoref{fig:unmarked,fig:marked} show an unmarked and a marked petri net graph.
\begin{figure}[H]
\begin{subfigure}[t]{0.45\textwidth}
  \centering
  \includegraphics[width=\textwidth]{petriNet/net/unmarked.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Unmarked}
  \label{fig:unmarked}
\end{subfigure}
~
\begin{subfigure}[t]{0.45\textwidth}
  \centering
  \includegraphics[width=\textwidth]{petriNet/net/marked.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Marked}
  \label{fig:marked}
\end{subfigure}
\caption{Example of unmarked and marked petri net graphs.}
\end{figure}

The marking of a petri net, can be represented as a
vector of the function $x$ applied on all places, for example the marking of the
\autoref{fig:marked} is the following vector $\mathbf{x}$

\begin{equation*}
\mathbf{x}=\begin{bmatrix}
  x(p_0)\\
  x(p_1)\\
  x(p_2)\\
  x(p_3)\\
  x(p_4)\\
  x(p_5)\\
  x(p_6)
\end{bmatrix} =
\begin{bmatrix}
  1\\
  0\\
  1\\
  0\\
  0\\
  2\\
  0
\end{bmatrix}
\end{equation*}

This vector $\mathbf{x}$, the marking of the petri net, can be identified as the
state of the petri net. So, different configurations of tokens mean different
states of the system, now we only need a way to change from a state to other, in
other words, move the tokens.

\subsubsection{Firing Transitions}
\label{sec:firingTransitions}
The mean of move the tokens is firing transitions. When an event  happens and
the corresponding transition is enabled, this transition is fired and tokens
are moved between places.
We can define the functions $I : T \rightarrow 2^P$ and $O : T \rightarrow 2^P$ that
describe the set of places considered as inputs and outputs of a transition: 
\begin{align*}
  I(t_j)= \{p \in P : Pre(p,t)> 0\}\\
  O(t_j)= \{p \in P : Post(p,t)> 0\}\\
\end{align*}
\begin{definition}[Enabled transition]
  \label{def:enabledTransition}~\\
  A transition is enabled if
  \[ x(p_i)\geq Pre(p_i,t_j) \text{ for all }{p_i \in I(t_j)}\]
  if $I(t_j)=\emptyset$, $t_j$ is always enabled. 
\end{definition}

And we can define the dynamic of the petri net, how the tokens move: 

\begin{definition}[Petri net dynamics]
  \label{def:petriNetDynamics}~\\
   It is possible to define a \emph{state transition}
  function, $f : \mathbb{N}^n \times T \rightarrow \mathbb{N}^n$  , where $n$ is
  the length of the state vector $\mathbf{x}$. This function $f$ is defined for
  a transition $t_j \in T$ if and only if this transition is enabled. If
  $f(\mathbf{x},t_j)$ is defined, then we create a new state vector
  $\mathbf{x}^\prime$:

  \[ x^\prime(p_i) = x(p_i) - Pre(p_i,t_j) + Post(p_i,t_j), i=1,\dots n \]
\end{definition}
  
As an example we can take \Autoref{fig:petriNetDynamics}:
\begin{figure}[H]
  \centering
 \begin{subfigure}[t]{0.45\textwidth}
  \centering
  \includegraphics{petriNet/net/beforeFiring.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Before firing.}
  \label{fig:beforeFiring}
\end{subfigure}
~
\begin{subfigure}[t]{0.45\textwidth}
  \centering
  \includegraphics{petriNet/net/afterFiring.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{After firing.}
  \label{fig:afterFiring}
\end{subfigure}
  \caption{Example of petri net Dynamic.}
  \label{fig:petriNetDynamics}
\end{figure}
The state before firing transition $t_0$ is $\mathbf{x}=\begin{bmatrix}3&
  0\end{bmatrix}^T$ and as we see $Pre(p_0,t_0)=2$ and $Post(p_1,t_0)=1$ so
applying the petri net dynamic we can find the next state $\mathbf{x}^\prime=\begin{bmatrix}1&
  1\end{bmatrix}^T$

Once all these fundamentals are presented we can finally define a Petri Net

\begin{definition}[Petri net]
  \label{def:petriNet}~\\
  A Petri net is defined as a five-tuple
  \[PN = (P,T,Pre,Post,\mathbf{x}_0)\]
  where: \\
  \indent $P$ is the set of \textbf{places} \\
  \indent $T$ is the set of \textbf{transitions} \\
  \indent $Pre$ is the \textbf{input incidence} function  \\
  \indent $Post$ is the \textbf{output incidence} function\\
\indent $\mathbf{x}_0$ is the initial marking of the net \\
And its dynamic is ruled by the \emph{state transition} function $f$ defined at \ref{fig:petriNetDynamics}.

\end{definition}

To make the connection between the Petri net and the events of the system, called $\Sigma$, the alphabet, we can
define a labeling function, $l : T^* \rightarrow \Sigma^*$ that makes the link between a
sequence of firing transitions and a sequence of events. But each transition
can only have one respective event. 

\begin{definition}[Labeled Petri net]
  \label{def:petriNet}~\\
  A Labeled Petri net is defined as a seven-tuple
  \[PN = (P,T,Pre,Post,\mathbf{x}_0,\Sigma,l)\]
  where: \\
  \indent $(P,T,Pre,Post,\mathbf{x}_0)$ is a Petri Net\\
  \indent $\Sigma$ is the set of \textbf{events} \\
  \indent $l$ is the \textbf{labeling} function  \\
\end{definition}

Usually the events are represented in the petri net graph over its respective
transition as shown in the \autoref{fig:labeledPetriNet}. This system has an alphabet
$\Sigma=\{a,b\}$ and labeling functions $l(t_0)=a$ and $l(t_1)=b$.

\begin{figure}[H]
  \centering
  \includegraphics{petriNet/labeled/labeled.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Labeled Petri net.}
  \label{fig:labeledPetriNet}
\end{figure}

\section{Control Interpreted Petri Nets}
\label{sec:cipn}
One of the greatest uses of Petri Nets, besides modeling a system, is its
ability to model the control of a system. For this intent we use Control Interpreted Petri nets. It is an
extension from the labeled Petri net, we add actions for places, so it is
possible to change the outputs of the system, conditions to the transitions, so it
is possible to change the state of the control based on the inputs of the
system, and even the ability to delay the firing transitions based on time.
Another artifice used is an inhibitor arc, that prevents the firing of a
transition based on the marking of the corresponding place.

\begin{definition}[Control Interpreted Petri net]
  \label{def:cipn}~\\
  A Labeled Petri net is defined as a seven-tuple
  \[PN = (P,T,Pre,Post,\mathbf{x}_0,In,\Sigma,C,l_C,D,L_D,A,I_A)\]
  where: \\
  \indent $(P,T,Pre,Post,\mathbf{x}_0)$ is a Petri Net\\
  \indent $In$ is the \textbf{inhibitor arc} function that prevents the
  enablement of transitions \\
  \indent $\Sigma$ is the set of \textbf{events} associated to transitions \\
  \indent $C$ is the set of \textbf{conditions} associated to transitions \\
  \indent $l_C$ is the \textbf{labeling} function that associates a transition
  with events and conditions from $\Sigma$ and $C$\\
  \indent $D$ is the set of \textbf{delays} associated to transitions \\
  \indent $l_D$ is the \textbf{labeling} function that associates a transition with a delay from $D$ \\
  \indent $A$ is the set of \textbf{actions} associated to places \\
  \indent $l_A$ is the \textbf{labeling} function that assigns actions from $A$ to a place \\
\end{definition}
The definition of $In : (P \times T )\rightarrow\mathbb{N}$ is that a transition
$t_j$ is inhibited if $x(p_i)\geq In(p_i,t_j)$. Inhibitor arcs are not used in
this work but usually they are represented with an arc with a circle in one of
its ends, as shown in \autoref{fig:inhibitor}.

\begin{figure}[H]
  \centering
  \includegraphics{petriNet/inhibitor/inhibitor.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{Example of Petri net with inhibitor arc.}
  \label{fig:inhibitor}
\end{figure}
As we can see from the definition there are two labeling functions to connect 
transitions, $l_C$ and $l_D$. The $l_c$ is defined for transitions with no
firing delay and $l_D$ for transitions with firing delay.

The labeling function $l_C : T^0\rightarrow(\Sigma \times C)$ defines a pair of
event and boolean condition from $\Sigma$ and $C$ respectively. A transition
$t_i$ belonging to $T^0$ (a subset of $T$ that represents the transitions with
no time delay) has a corresponding event, condition tuple $(\sigma_i,c_i)$
For example, take a transition $t_0$, $\Sigma =\{\sigma_0\}$ and $C=\{c_0\}$. If
a function $l_c(t_0)=(\sigma_0,c_0)$ is defined, this transition will be fired
when the condition $c_0$ is true and the event $\sigma_0$
happens, but obviously, if and only if this transitions is enabled and not
inhibited. The transition $t_0$ is represented graphically as shown in \autoref{fig:condition}

\begin{figure}[H]
  \centering \includegraphics[width=0.3\textwidth]{petriNet/cipn/condition.tikz}
  \caption{Representation of new labeling function}
  \label{fig:condition}
\end{figure}

If the event is missing from the representation of the transition, it is equal
to the $\lambda$
, the always occurring event. And if the condition is missing, that means it is
equal to $1$, it is always $true$. If both are missing, that means the
transition will be automatically executed if it is enabled. 

By the other hand, the labeling function $l_D : T^D \rightarrow D$, defines a delay for the
transition to be fired. A timed transition $t_i$, a transition in $T^D$ (a subset of T
that represents the transitions with a time delay), has a corresponding delay
$d_i$. As an example, take a timed transition $t_1$ and $D=\{d_1\}$, after the
enablement of the transition, it takes $d_1$ time units in order to be fired. In
this work timed transitions are represented as bars slightly larger than normal
conditions. An example of this representation we can see \autoref{fig:timedtransition}

\begin{figure}[H]
  \centering \includegraphics[width=0.3\textwidth]{petriNet/cipn/timedtransition.tikz}
  \caption{Representation of a timed transition.}
  \label{fig:timedtransition}
\end{figure}
Another labeling function that was created is $l_A : P\rightarrow 2^A$,
assigning a set of actions belonging to $A$ to a place. Actions can be impulse actions or continuous. A
continuous action happens always that the marking of a place is greater than 0,
$x(p_i)>0$, an impulse action, on the other hand, happens only when the marking of
the place changes from 0 to a value greater than 0. 
Actions are represented graphically as labels in places. Impulse actions are differed by a star (*) at its end. So an action $F$ is
continuous and $B^*$ is an impulse action. 
\autoref{fig:actions} show a representation of a Place with both kinds of actions.
\begin{figure}[H]
  \centering \includegraphics[width=0.3\textwidth]{petriNet/cipn/actions.tikz}
  \caption{Representation of labeling of Actions.}
  \label{fig:actions}
\end{figure}

Although these representations exist, in this work events, conditions and
actions labels are suppressed from the diagrams and tables accompany the drawings
showing the meaning of the transitions (firing events and conditions) and places
(Actions). This choice was made because when the controlled interpreted Petri nets
are very
large as the ones shown in the next chapters, if the events, conditions and
actions labels are long they can increase the size of the
diagram.

To illustrate this better we give an example based on one example from \cite{david1989grafcet}.
\begin{example}[Loading of a wagon] ~\\
  \label{ex:loadingOfAWagon}
We consider the system represented by the scheme in
\autoref{fig:cipnexamplescheme}. A wagon can be moved between the points $a$ and
$b$, using the inputs $L$ and $R$ (moving it to the left or right,
respectively). At point $a$ there is a button $m$ that can be pressed by an
operator and a limit switch called $a$ that is activated when the wagon is on
the left. At point $b$, an homonym limit switch is placed and activated when the
wagon is on the right. There is a hopper that can
be opened when the input $Open$ is turned on and closed when not.If it is opened
its content is poured. There is also a
button $p$ that is activated when the weight applied over the plate is equal or
greater to the weight of a full wagon. 

The objective of the control is, when the wagon is in its leftmost position and
the button $m$ is pressed, it moves to the right, stops at $b$, the hopper is
opened and the wagon is loaded, when it is completely full it moves to the left
and it stops at $a$ waiting to be unloaded and for a next press of $m$ to recommence
the loop. 
\end{example}


\begin{figure}[H]
  \centering \includegraphics[width=0.8\textwidth]{cipnExample/scheme.tikz}
  \caption[cipnexample]{Example of System to be controlled by the Petri Net}
  \label{fig:cipnexamplescheme}
\end{figure}
From the description of the control it is possible to create a Control Interpret
Petri Net to describe it, as the one in \autoref{fig:cipnexample}


\begin{figure}[H]
  \centering \includegraphics[width=0.8\textwidth]{cipnExample/cipn.tikz}
  \caption[cipnexample]{Example of Control Interpreted Petri Net to control
    system in \autoref{fig:cipnexamplescheme}}
  \label{fig:cipnexample}
\end{figure}

The meaning\slash description of each place and transition is given by the
following tables:

\input{../../figures/cipnExample/cipnPlaces}
\input{../../figures/cipnExample/cipnTransitions}

In this work as in the usual boolean notation, when just the name of a variable is given in a table it means the
variable is equal to true, and when there is a bar in its top it is equal to
false, so they determine conditions. E.g.: $b$ and $\overline{b}$.
And when a variable is preceded by $\uparrow$ and $\downarrow$, they  determine
events corresponding to its raising and falling edge.

\usetikzlibrary{arrows,shapes,circuits.plc.ladder,external}

\section{Implementation of Control Interpreted Petri Nets}
\label{sec:implementPetriNets}
Once the control of a system is modeled by a \CIPN, it
is needed to implement the control in a real controller. The most used
controllers in the industry are \PLCs. The international standard IEC 61131,
defines all the standards for \PLCs, and its third part (IEC 61131-3) defines
five languages to program \PLCs: \LD, Function Block Diagram
(FBD),  Structured Text (ST), Instruction List (IL) and Sequential Function
Chart (SFC). One of the most used in the industry is \LD, because of its
resemblance with electric connections. So we are going to use \LD{} to implement the
control designed with the \CIPN.

\subsection{Ladder Logic}
\label{sec:ladder}

The ladder logic is based on two components, contacts and coils. Their terminals are
interconnected to transmit boolean signals. This connection is similar to the
ladder physical implementation, from where came its inspiration, the components
were connect to boards and they formed electric circuits, turning on and off
motors and other actuators, based on the combination of its inputs. The name
Ladder comes from the resemblance between its structure (circuits formed in
parallel one above the other) and a ladder, so each circuit is called a Rung by analogy. The logic
values in a \LD{} rung
are transmitted from the left to the right of the diagram. The components let
the logic ``current'' flow from its left terminal to the right terminal
depending on some conditions, and these conditions vary from component to
component.
The rungs are executed one by one and once the very last rung is executed,
the first rung is re-executed, thus creating an infinite loop. 
 The graphical representation of the most used types of contacts and coils
can be seen in \Autoref{fig:contacts,fig:coils}

\newlength{\ladderskip}
\newlength{\ladderrungsep}

% Types of Contacts
\begin{figure}[H]
\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/contactNO.tikz}
  \caption{Normally Opened Contact.}
  \label{fig:contactNO}
\end{subfigure}
~
\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/contactNC.tikz}
  \caption{Normally Closed Contact.}
  \label{fig:contactNC}
\end{subfigure}
\vspace{1em}

\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/contactP.tikz}
  \caption{Positive Edge Contact.}
  \label{fig:contactP}
\end{subfigure}
~
\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/contactN.tikz}
  \caption{Negative Edge Contact.}
  \label{fig:contactN}
\end{subfigure}

  \caption{Types of Contacts.}
  \label{fig:contacts}
\end{figure}

% Types of Coils
\begin{figure}[H]
\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/coilNO.tikz}
  \caption{Coil.}
  \label{fig:contactNO}
\end{subfigure}
~
\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/coilNC.tikz}
  \caption{Negated Coil.}
  \label{fig:contactNC}
\end{subfigure}
\vspace{1em}

\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/coilSet.tikz}
  \caption{Set (latch) Coil.}
  \label{fig:contactP}
\end{subfigure}
~
\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/coilReset.tikz}
  \caption{Reset (unlatch) Coil.}
  \label{fig:contactN}
\end{subfigure}

  \caption{Types of Coils.}
  \label{fig:coils}
\end{figure}

\subsubsection{Contacts}
Contacts represent the conditions of the ladder logic depending on inputs. These inputs can be any variable in a
\PLC, an external input ( sensors of the system to be controlled), a variable stored in memory or the current
value sent to an output from the \PLC. A normally opened contact
activates its right terminal (set it to $true$) if the logic value in its left terminal
is $true$ and its corresponding input is equal to $true$ 
A normally closed contact activates its right terminal if the logic value in its
left terminal is $true$ and its corresponding input is equal to $false$.
The Positive Edge contact activates its right terminal only in the instant that
its input change from logic value $false$ to $true$, if the logic value in its
left terminal is $true$. And the Negative Edge contact activates its right
terminal only in the instant that its input change from logic value $true$ to
$false$.

As we can see, positive and negative contacts can be used to represent raising ($\uparrow$)
and falling edge  ($\downarrow$) events and normally opened and closed contacts
to represent conditions (and their negation).

\subsubsection{Coils}

Coils, by the other side represent the actuation in outputs. These
outputs can be a variable stored in memory or the outputs
of the controller (actuators of the system to be controlled, for instance). 
A coil sets its output variable to true if the logic value of its left terminal is $true$,
and sets the output to $false$ otherwise.
A negated coil does the exact opposite, sets the output value to true if the logic
value of its left terminal is $false$ and sets it to $true$ if the logic is
$true$.

A set coil (or latch) sets its output variable to $true$ if the logic value of its
terminal is $true$ and it remains $true$ until the variable is reset.
And a reset coil (or unlatch) sets its output variable to $false$ if the logic
value of its terminal is $true$ and it remains $false$ until the variable is
set.

\subsubsection{Combinational Logic}
In boolean logic, in order to show functional completeness, it is need to show a
complete set of connectives ( a set that can create all other logic connectives
as a combination of its elements ). A well-know complete set is $S=\{AND,NOT\}$,
binary conjunction and negation.
To show that the ladder logic is functional complete we need only to present how
to construct this two connectors in it.
The conjunction of two inputs, can be made using two contacts in series, as
shown in \autoref{fig:ladderSeries}
\begin{figure}[H]
  \centering \includegraphics{ladder/series.tikz}
  \caption{And logic in a Ladder rung.}
  \label{fig:ladderSeries}
\end{figure}
In this case C will only be activated if A and B are equal to $true$. ($C=AB$)

The negation of a variable can be achieved by the use of a normally closed
contact (\autoref{fig:ladderNot}).
\begin{figure}[H]
  \centering \includegraphics{ladder/not.tikz}
  \caption{Not logic in a Ladder rung.}
  \label{fig:ladderNot}
\end{figure}
C will only by activated if A is $false$. ($C=\overline{A}$)

Although all logic connectives can be constructed with this two connectors, the
OR connector can be achieved by the use contacts in parallel (\autoref{fig:ladderParallel}).
\begin{figure}[H]
  \centering \includegraphics{ladder/parallel.tikz}
  \caption{Or logic in a Ladder rung.}
  \label{fig:ladderParallel}
\end{figure}



\subsubsection{Function Blocks and extensions}
In order to increase functionality some function blocks and 
extensions to contacts were created. We can see examples of theses blocks and
contacts in the next figure:

\begin{figure}[H]
   \centering
\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/ctu.tikz}
  \caption{Up counter.}
  \label{fig:ctu}
\end{subfigure}
~
\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/ton.tikz}
  \caption{On-delay timer.}
  \label{fig:ton}
\end{subfigure}

\begin{subfigure}[t]{0.45\textwidth}
  \centering \includegraphics{ladder/comp.tikz}
  \caption{Less or equal comparator.}
  \label{fig:comp}
\end{subfigure}
  \caption{Examples of function blocks.}
  \label{fig:functionBlocks}
\end{figure}

Up counters (\autoref{fig:ctu}) save the value of a counter in a $CV$ variable. Every raising edge
on input $CU$ it increments $CV$ value. If $CV=PV$, the logic value of output $Q$ 
is set to $0$. When the input $R$ is true $CV$ value is set to $0$ and the
output $Q$ set to false.

On-delay timers (\autoref{fig:ctu}) set a timer when input $IN$ is $true$
and save it to $ET$. If $ET=PT$, the logic value of output $Q$ is set to $true$.
But if, meanwhile the counting, the value of $IN$ returns to $false$, $ET$ is reset to
$0$.

Comparator contacts as the less or equal comparator in \autoref{fig:comp}, work
similarly to contacts, but instead of an input as a condition, there are two
inputs ($value1$ and $value2$) and the condition is a comparison between both of
them. In this case, the contact is activated once its left terminals' logic
value is $true$ and $value1\leq value2$.

Other blocks and functions can be found in the IEC 61131-3, as adders,
subtractors, communication blocks etc.

\subsection{Conversion from \CIPN{} to \LD}
\label{sec:cipnToLD}

A simple method of conversion from \CIPN{} to \LD{} is presented in
\cite{moreira2013bridging}.

It consists in dividing the \CIPN{} in 4 modules:
\begin{enumerate}
\item A module of external events\\
  To create conditions to the firing of transitions based on external events
  (inputs)
\item A module of firing conditions\\
  To indicate what condition will be fired using the $Pre$, and $In$ functions, the conditions found on the
  last module and time delays (if it is a timed transition 
  )
\item A module of Petri Net dynamics\\
Uses the $Pre$ and $Post$ functions to determine the tokens ``motion''
\item A module of actions\\
  Determines the places where each action is performed.
\end{enumerate}
In this work, the external events and firing conditions was combined in order to
reduce the size of the program. But every module will be described as in
\cite{moreira2013bridging}.

\subsubsection{External events}
As external events are associated with positive and negative edge of the inputs
of the system, in this module, positive and negative edge contacts are used to
detect the rising and falling edge events, and they are stored in variables
using coils, a variable is created for every event.
For visibility's and organisation's sake a rung is used for each event,
resulting $|\Sigma|$ rungs. 
\subsubsection{Firing Conditions}
As said in \ref{sec:cipn}, for a transition $t_j$ to be fired, first it needs to be
enabled ($x(p_i)\geq Pre(p_i,t_j)$ for all $p_i\in I(t_j)$), not inhibited
($x(p_i)< In(p_i,t_j)$ for all $p_i\in I(t_j)$) and the conditions and events
$\sigma_jc_j$ are met or the delay $d_j$ is elapsed, depending on the kind of
transition.
As places can have multiple tokens, we can use $int$ variables to store the
number of tokens, and comparator contacts to determine if the transitions are
enabled and not inhibited.
When a place can only bear at most one single token for all markings of the
Petri net, a $bool$ variable can be used to store the number of tokens, in this
case a single normally open contact can be used to determine if there is a token
in that place.
The time delays are implemented using on-delay
timers. The state of fulfilment of the conditions is stored in variables, one
for each transition.
Similarly, for organisation's sake a rung is used for each transition, resulting
$|T|$ rungs.
\subsubsection{Petri Net Dynamics}
In this module the dynamic of the tokens is implemented. If the condition for
the firing of a transition is fulfilled (represented by normally open contacts), adders and subtractors
can be used to represent the movement of tokens, increasing and decreasing the
values from the $int$ variables that represent the marking
of each place, if their capacity is greater than one, if not they are
represented by boolean variables, and instead Set and Reset coils can be used to
represent a token entering a place and a token exiting another, respectively.
Again, for organisation's sake a rung is associated for each transition,
resulting $|T|$ rungs.

\subsubsection{Actions}
In the Action module, we use coils to act on the outputs. Depending on the type
of action and the logic of the control, set\slash reset coils or normal coils
can be used. The condition to activate\slash deactivate the output is the
presence of a token in the places where the action is performed, this can be
achieved by comparing the numbers of tokens in a place. If the tokens of a
place is represented by an $int$ variable, we use greater or equal comparators,
but if it is represented by a $bool$ variable, a normally opened contact is
enough. If the action is an impulse action we can put a positive edge in series
with the places contact or the comparator.

Differently from the original article, we will use one rung per
each action in A, resulting in $|A|$ rungs. This is made because in
\cite{renault2017regles} it is recommended to perform an action in only one
rung, and group the conditions using OR connectors.
In the industry this is important in order to reduce errors and to ease the
debugging process.

\subsubsection{Example}

An example of this conversion can be given using the same \CIPN{} from example 
\ref{ex:loadingOfAWagon}. As said, the external events and firing condition
modules are grouped in same module in this work. The converted Ladder Logic
can be seen in \autoref{fig:cipnexampleLadder}.
\begin{figure}[H]
  \centering \includegraphics{cipnExample/cipnLadder.tikz}
  \caption[cipnexample]{Example of Control Interpreted Petri Net converted to
    Ladder.}
  \label{fig:cipnexampleLadder}
\end{figure}

\subsection{Petri Net divided in multiple PLCs}
\label{sec:multiplePlcs}
A problem that can occur, is the case where a \CIPN{} must be divided in
multiple \PLCs, because of how the assembling of the plant was (some
inputs\slash outputs are only
connected to a single \PLC, and other inputs\slash outputs to another \PLC),
this division can be arbitrarily decided by the
person who will implement the control.

In \autoref{fig:communicationPlcPN}, it is shown an example of a \CIPN{} divided
between 2 \PLCs.
As we can see, in \Autoref{fig:communicationPlcPN1,fig:communicationPlcPN2}
there are dotted transitions and places. In this work, we will represent as
dotted, transitions and places that are part of another section of the Petri
Net. They are not represented in the same figure, 
but the arcs show the connection between the sections of the net, showing that
when connected they form a complete Petri net. In the digital form\footnote{Available at: \url{https://github.com/Accacio/docsTCC/raw/master/monografia.pdf}}  of this thesis it is possible to travel between
figures that are not in the same page just by clicking in the name of the
corresponding dotted place\slash transition.
\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{0.5\textwidth}
    \center
    \includetikzfigure[width=\textwidth]{communicationPlcPN/communicationPlcPN}
    \caption{Petri Net on PLC 1.}
    \label{fig:communicationPlcPN1}
  \end{subfigure}%
  ~
  \begin{subfigure}[t]{0.5\textwidth}
    \centering
    \includetikzfigure[width=\textwidth]{communicationPlcPN/communicationPlcPN1}
    \caption{Petri Net on PLC 2.}
    \label{fig:communicationPlcPN2}
  \end{subfigure}
  \caption{Example of Petri Net divided between 2 PLCs.}
  \label{fig:communicationPlcPN}
\end{figure}

In order to solve the problem of communication caused by the division, there are
different ways, one of them is the method shown by \cite{antunesfloriano2019sincronizacao}, where
different sections are synchronised in a distributed manner using common places.
In this work, a master\slash slave approach was used. CLP1 was considered as the
master and CLP2 as a slave. For the master, it is created another module
called ``Data Sending\slash Receiving'', divided in 2 parts, the first that
happens before all other modules, with the objective of getting all needed
variables from other \PLCs, and another part, that happens after all other
modules, with the objective of sending variables to all other \PLCs.
By the other side, the slaves have 2 modules, one at the beginning, called
``Prepare Received Data'' and another at the very end called ``Prepare Data to
Send'', in which the data received from the master is prepared to be used and
the data is prepared to be sent to master.

The communication between \PLCs{} can be made using Profinet protocol, and if we
take for instance Siemens \PLCs, they have two function blocks called ``Get'' and
``Put'', that are used to establish data transfer between two \PLCs{} using the
Profinet protocol. Tutorials on how to configure this blocks can be found on \citep{antunesfloriano2019sincronizacao,oliveira2016protocolo,rochapereira2019automacao}.


The basic idea is to transfer the state of the variables that determine the
conditions of firing transitions between both \PLCs. The problem is that as the
two \PLCs are not in sync, the condition of a firing transition could change in
the middle of the logic. So, in order to circumvent it, we can duplicate those
variables in the slave PLC, and in the ``Prepare Received data'' module update
the values of these variables (using positive edges contacts), forcing them to
be updated only once in each loop and when their value are changed from $0$ to
$1$.

When a transition change the value of tokens in more than one \PLCs, as $t_1$,
an auxiliary variable is created in order to create a kind of
acknowledgement\slash permission 
from the master, as an ``ok, you can proceed'' to the slaves to perform the
dynamic of that transition.

The example of those three new modules are shown in \autoref{fig:communicationPlcPNLadder}

\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics{communicationPlcPN/communicationPlcPNLadder.tikz}
    \caption{Ladder Logic on PLC 1.}
    \label{fig:communicationPlcPN1Ladder}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics{communicationPlcPN/communicationPlcPN1Ladder.tikz}
    \caption{Ladder Logic on PLC 2.}
    \label{fig:communicationPlcPN2Ladder}
  \end{subfigure}
  \caption{Example of Petri Net divided between 2 PLCs.}
  \label{fig:communicationPlcPNLadder}
\end{figure}
  
As we can expect, this kind of logic of master\slash slave works well when
there are 2 \PLCs, but when there are more \PLCs, this centralised approach
creates a single point of failure and as the master \PLC{} works as a hub, it
increases the communication delay. When there are more than two \PLCs{} it is
preferable to use a distributed approach as the one shown in
\cite{antunesfloriano2019sincronizacao}.

\section{Identification}
\label{sec:identification}

Once the control is implemented and the system is working as it should, we
arrive at the objective of this work, the identification of the system.
As said in the introduction, this work is based on \cite{moreira2018enhanced}.
In this article, a new model for \DES{} identification is proposed, called
\glsreset{DAOCT}\DAOCT. This model was created with aim of fault detection based
on the observation of the fault free behaviour of the system, as in the models
proposed by 
\cite{roth2009fdi} and \cite{klein2005fault}, but its use of paths increases the
efficiency for fault detection when compared with the latter articles.

This fault free observation is made by the acquisition of the observable signals
of the system (controller inputs and outputs) for a sufficiently long
period of time while the system works normally. These signals can be seen on \autoref{fig:obsSignals}.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
        % \draw[help lines,xstep=1,ystep=1] (0,0) grid (10,10);
        % \foreach \x in {0,1,...,10} { \node [anchor=north] at (\x,0) {\x}; }
        % \foreach \y in {0,1,...,10} { \node [anchor=east] at (0,\y) {\y}; }
        
        \draw[ultra thick,rounded corners] (3.5,0) rectangle (6.5,1.5);
        \draw[ultra thick,rounded corners] (0.5,2) rectangle (3.5,3.5);
        \draw[ultra thick,rounded corners] (6.5,2) rectangle (9.5,3.5);
        \draw[ultra thick,rounded corners] (3.5,4.5) rectangle (6.5,6);
        \draw (5,5.25) node {Controller};
        \draw (5,0.75) node {Plant};
        \draw (2,2.75) node {Actuators};
        \draw (8,2.75) node {Sensors};

        % actuators to plant
        \draw[->,>=stealth, very thick] (2,2) -- (2,0.75) -- (3.5,0.75);

        % controller to actuators
        \draw[->,>=stealth, very thick] (3.5,5.25) -- (2,5.25) -- (2,3.5);

        % Plant to sensors
        \draw[->,>=stealth, very thick] (6.5,0.75) -- (8,0.75) -- (8,2);

        % Sensors to controller
        \draw[->,>=stealth, very thick] (8,3.5) -- (8,5.25) -- (6.5,5.25);

        \draw[->,>=stealth, very thick] (2,4) -- (10,4);
        \draw[fill] (2,4) circle(.05);

        \draw[->,>=stealth, very thick] (8,4.5) -- (10,4.5);
        \draw[fill] (8,4.5) circle(.05);

        \draw (11,4.5) node {Observed};
        \draw (11,4.15) node {signals};

        \draw (1.5,5.75) node {Controller outputs};
        \draw (8.5,5.75) node {Controller inputs};

    \end{tikzpicture}
  \caption{Observed Signals in a closed-Loop \DES.}
    \label{fig:obsSignals}
  \end{figure}

First, we assume the controller have $m_i$ binary inputs, $i_h$, for $h=1,\dots,m_i$ and $m_o$ binary
outputs, $o_h$, for $h=1,\dots,m_o$, and we create a Input\slash Output vector called $\mathbf{u}$, that varies with
time:

\begin{equation*}
\mathbf{u}(t_1)=
\begin{bmatrix}
  i_1(t_1)&
  \dots&
  i_{m_i}(t_1)&
  o_1(t_1)&
  \dots&
  o_{m_o}(t_1)
\end{bmatrix}^T
\end{equation*}
\newcommand{\vu}{\mathbf{u}}
 This vector $\mathbf{u}(t)$ represents the status of the system in a instant
 $t$. In the \DAOCT model, only untimed system models are considered, thus
 the status of the system can only be modified via system events, $\sigma$. To
 reduce the size of the notation $\mathbf{u}(t)$ is going to be represented as $\vu_t$. The
 transition between status in $t_i$ and $t_j$ is represented as ($\vu_i,\sigma,\vu_j$). If we have a sequence of
 $l$ input\slash output vectors, we have an observed path of the system,
 $p=(\vu_1,\sigma_1,\vu_2,\sigma_2,\dots,\sigma_{l-1},\vu_l)$.
So, if we observe multiple paths meanwhile our observation process, we can
create multiple paths
$p_i=(\vu_{i,1},\sigma_{i,1},\vu_{i,2},\sigma_{i,2},\dots,\sigma_{i,l_i-1},\vu_{i,l_i})$,
for $i=1,\dots,r$, where $r$ is the number of observed paths, and $l_i$ is the
number of vertices in each path $p_i$.

Supposing that all paths begin with the same I\slash O vector, that means, all
observations begin from the same status, it is possible to associate to each
path $p_i$ a sequence of events and a sequence of I\slash O vectors, called,
$s_i$ and $\omega_i$, and they are defined as:
\begin{align*}
  s_i&= \sigma_{i,1}\sigma_{i,2}\dots\sigma_{i,l_i-1} \\
  \omega_i&= \vu_{i,1}\vu_{i,2}\dots\vu_{i,l_i}
\end{align*}
Using these observed sequences of events $s_i$, we can define a language
, called observed language, $L_{Obs}$:

\begin{equation}
  L_{Obs}:= \bigcup^r_{i=1}\overline{\{s_i\}}
\end{equation}
\begin{observation}
If any sequence $s_i$ is the prefix of another sequence $s_j$, the path $p_i$ should
be discarded, along with $s_i$ and $\omega_i$, since it does not present any new
information for the identification process.
\end{observation}
The objective of identification is to find a model with a language that
can simulate this observed language. This language of the identified model is
called $L_{Iden}$.
We can describe this relation between these languages as $L_{Obs} \subseteq
L_{Iden}$.
As said in
\cite{moreira2018enhanced}, in finite time only part of the sequences  of events
the system can generate are observed. So we can define a language $L_{Orig}$,
the original language generated by the system, that we is never known.

From $L_{Orig}$ and $L_{Iden}$, we can define another language, an exceeding
language $L_{Exc}$, that is, part of the identified language that is not present in the
original language, $L_{Exc}=L_{Iden}\backslash L_{Orig}$.  The
relation between $l_{Orig}$ and $l_{Obs}$ is $L_{Obs} \subset L_{Orig}$. And from
these two languages we can define another language $L_{OrigNI}$, part of the
original language that was not identified, $L_{OrigNI}=L_{Orig}\backslash L_{Iden}$
The relation between all these languages is shown in \autoref{fig:languagesVenn}.

\usetikzlibrary{patterns}
\begin{figure}[H]
  \centering \includegraphics[width=0.5\textwidth]{vennDiagramLanguages.tikz}
  \caption{Venn diagram showing the relation between $L_{Orig}$, $L_{OrigNI}$,
    $L_{Obs}$, $L_{Exc}$ and $L_{Iden}$}
  \label{fig:languagesVenn}
\end{figure}
As $L_{Exc}$ represents a part of the identified language that is not part of
the original language, some faulty sequences will not be detected, as they are
part of the identified language. So in order to reduce the number of these non
detected faults, $L_{Exc}$ should have a cardinality as close to $0$ as it is
possible, this is possible by creating identification models that generate
smaller $L_{Exc}$.

And as $L_{OrigNI}$ represents the part of the original system that was not
identified, that means some sequences present on the fault-free behaviour of the
system will be detected as faults, generating false alarms. This language should
also be reduced, so the false alarms generated are reduced. As the original
language of the system is never known, it is very difficult to know for sure if
$L_{OrigNI}$ is small or not. \cite{klein2005fault} show that if a system is
observed for a sufficiently long time, there exists a number $n_0\in \mathbb{N}$
such that $L_{Orig}^{\leq n_0}\backslash L_{Obs}^{\leq n_0}\approx \emptyset$,
where $L_{Orig}^{\leq n_0}$ and $L_{Obs}^{\leq n_0}$ denote the languages formed
by all sequences of events of length smaller than or equal to $n_0$ of
$L_{Orig}$ and $L_{Orig}$. Since $L_{Obs}\subseteq L_{Iden}$, $L_{OrigNI}^{\leq
  n_0}$ is also approximately the empty set.

In this work we assume that all
sequences of events that have length $n_0+1$ were observed, thus
$L_{OrigNI}^{\leq n_0}=\emptyset$. So it leaves to the identification model the
sole problem of reducing the language $L_{Exc}^{\leq n_0}$ and $L_{Exc}$ consequentially.

\subsection{DAOCT}
In this subsection the modified automaton model proposed by
\cite{moreira2018enhanced} will be explained and the algorithm to construct it
by the observed paths $p_i$ will be described. 
The definition of the automaton is the following:
\begin{definition}[DAOCT]
  \label{def:daoct}~\\
  A Deterministic Automaton, denoted by DAOCT, is a nine-tuple
  \[ DAOCT = (X,\Sigma,f,\lambda,R,\theta, x_0,X_f)\] where:

  \indent X is the set of \textbf{states} \\
  \indent $\Sigma$ is the finite set of \textbf{events}\\
  \indent $\Omega \subset \mathbb{N}_1^{m_i+m_o} $ is the set of \textbf{I/O vectors}\\
  \indent $f:  X \times \Sigma^\star \rightarrow X$ is the \textbf{deterministic transition} function  \\
  \indent $\lambda : X \rightarrow \Omega$ is the \textbf{state output} function \\
  \indent $R = {1,2,\dots,r}$ is the set of \textbf{path indices} \\
  \indent $\theta : X \times \Sigma \rightarrow 2^R$ is the \textbf{path
    estimation} function \\
  \indent $x_0$ is the \textbf{initial state} \\
  \indent $X_f \subseteq X $ is the set of \textbf{final states}
\end{definition}

The sets of events and I\slash O vectors of each path $p_i$ are denoted $\Sigma_i$
and $\Omega_i$. Thus $\Sigma$ and $\Omega$ can be calculated by the union of
this sets: $\Sigma=\bigcup_{i=1}^r\Sigma_i$ and
$\Omega=\bigcup_{i=1}^r\Omega_i$.
From the vertices of the paths $p_i$, the I\slash O vectors, the states of the model are extracted.
Each vertex is chosen as a new state. But depending on the system, the vertices
can be repeated in different paths and even in the same path, so a kind of
memory of the past I\slash O vectors can be interesting to differentiate them,
that means, taking them as different status of the system. This kind of memory
is presented on the form of a sequence of I\slash O vectors that stores a
certain number of the past ones. To determine the number of vectors stored in this sequence an
arbitrary variable $k$, a free parameter, is created. 
The modified paths created by substituting the vertices for these sequences of
I\slash O vectors are
denoted $p_i^k$ and are defined as follows:
\begin{equation}
  \label{eq:modifiedPath}
 p_i^k= (y_{i,1},\sigma_{i,1},y_{i,2},\sigma_{i,2},\dots,\sigma_{i,l_1-1},y_{i,l_i}) 
\end{equation}
where 
\begin{equation}
  \label{eq:modifiedPathb}
y_{i,j}=\begin{cases}
    (\vu_{i,j-k+1},\dots,\vu_{i,j}),& \quad \text{if } k\leq j\leq l_i\\
    (\vu_{i,1},\dots,\vu_{i,j}),  & \quad \text{if } j<k
  \end{cases}
\end{equation}

\begin{observation}
Depending on the choice of the value of $k$, some characteristics can be
observed on $p_i^k$. For instance, if $k=1$, $p_i^k=p_i$. And if $k$ is equal to
the larger $l_i$, then all $y_{i,l_i}$ are composed with all vertices of its
corresponding path $p_i$.
\end{observation}

As an example of the computation of the paths $p_i^k$, we can take the observation of the following
paths, from \cite{moreira2018enhanced}:
\newcommand{\colvec}[2][1]{%
  \scalebox{#1}{%
    \renewcommand{\arraystretch}{.7}%
    $\begin{bmatrix}#2\end{bmatrix}$%
  }
}
\setlength\arraycolsep{2pt}
\begin{align*}
  p_1&= \left(\colvec{1\\0\\0},a,\colvec{1\\1\\0},b,\colvec{0\\1\\1},c,\colvec{0\\0\\0},d,\colvec{0\\0\\1},e,\colvec{1\\0\\0}\right) \\
  p_2&= \left(\colvec{1\\0\\0},g,\colvec{0\\0\\0},h,\colvec{1\\1\\0},b,\colvec{0\\1\\1},c,\colvec{0\\0\\0},i,\colvec{1\\0\\0},j,\colvec{0\\1\\1},l,\colvec{1\\0\\0}\right) \\
  p_3&= \left(\colvec{1\\0\\0},g,\colvec{0\\0\\0},h,\colvec{1\\1\\0},b,\colvec{0\\1\\1},i,\colvec{1\\1\\1},m,\colvec{0\\0\\0},d,\colvec{0\\0\\1},n,\colvec{1\\1\\0}\right) \\
\end{align*}
The events of each path is associated with the rising or the falling edges of
the controller signals. The event $a$ represents the rising edge of the second
controller signal, that is $a=\uparrow$2 and the event $l$ the rising edge of the first
controller signal and the falling edge of the second
and third controller signals, $l=\uparrow$1$\downarrow$2$\downarrow$3.

As said, for $k=1$, $p_i^k=p_i$, so in order to better illustrate the
construction of $p_i^k$, we choose $k=2$. Using \Autoref{eq:modifiedPath,eq:modifiedPathb} we can
obtain the following modified paths: 
\begin{align*}
  p_1^2&= \left(\colvec{1\\0\\0},a,\colvec{1&1\\0&1\\0&0},b,\colvec{1&0\\1&1\\0&1},c,\colvec{0&0\\1&0\\1&0},d,\colvec{0&0\\0&0\\0&1},e,\colvec{0&1\\0&0\\0&0}\right) \\
  p_2^2&= \left(\colvec{1\\0\\0},g,\colvec{1&0\\0&0\\0&0},h,\colvec{0&1\\0&1\\0&0},b,\colvec{1&0\\1&1\\0&1},c,\colvec{0&0\\1&0\\1&0},i,\colvec{0&1\\0&0\\0&0},j,\colvec{1&0\\0&1\\0&1},l,\colvec{0&1\\1&0\\1&0}\right) \\
  p_3^2&= \left(\colvec{1\\0\\0},g,\colvec{1&0\\0&0\\0&0},h,\colvec{0&1\\0&1\\0&0},b,\colvec{1&0\\1&1\\0&1},i,\colvec{0&1\\1&1\\1&1},m,\colvec{1&0\\1&0\\1&0},d,\colvec{0&0\\0&0\\0&1},n,\colvec{0&1\\0&1\\1&0}\right) \\
\end{align*}

As we can see, comparing the vertices from $p_i$ with the vertices from $p_i^k$,
the number of unique vertices from the latter is greater than the number from the former.

As presented, the states of the system are extracted from these vertices, in order to
do so a labelling function is defined, denoted $\tilde{\lambda}$, which
definition is $\tilde{\lambda}:X\rightarrow \Omega^k$. Where $\Omega^k$ is
formed by all sequences of $\Omega$ of length smaller than or equal to $k$. This
function $\tilde{\lambda}$ associates a sequence of I\slash O vectors $\omega^k
\in \Omega^k$ to each state $x \in X$. And we can denote $\tilde{\lambda_l}(x)$
as the last vector of $\tilde{\lambda}(x)$.

These functions are used in the
identification algorithm of the \DAOCT{} model. This identification algorithm, adapted from
\cite{moreira2018enhanced}, is presented in algorithm \ref{alg:identification}.


\vspace{1cm}
\begin{algorithm2e}[H]
  \caption{Identification Algorithm}\label{alg:identification}
  \KwIn {%
    Modified observed paths $p_i^k$, for i= 1,\dots,$r$ } \KwOut {%
    DAOCT =
    $($\XSet,\SigmaSet,\OmegaSet,\ffunction,\lambdafunction,\RSet,\thetafunction,\xZero,\XfSet$)$
  } \BlankLine Create an initial state $x_0$, and define $\lambda(x_0) =
  \tilde{\lambda}(x_0) = y_{1,1}$

  $X = \{ x_0\}, X_f = \emptyset, R = \emptyset$

  \For{$i = 1$ \KwTo $r$} { $R = R \cup \{ i \}$
  
    \For{$j = 1$ \KwTo $l_i - 1$} { Find the State $x \in X $ such that
      $\tilde{\lambda}(x) = y_{i,j+1}$

      \eIf{$\tilde{\lambda}(s) \neq y_{i,j+1}$ for all $ s \in X$} { Create
        state $x^\prime$ and define $\tilde{\lambda}(x^\prime) = y_{i,j+1}$

        $X = X \cup \{ x^\prime\}$

        $\lambda(x^\prime) = \tilde{\lambda_l}(x^\prime)$

      } { Find $x^\prime \in X$ such that $\tilde{\lambda}(x^\prime) =
        y_{i,j+1}$ } $f(x,\sigma_{i,j}) = x^\prime$

      Add $i$ to $\theta(x,\sigma_{i,j})$

      \If{$j = l_i - 1$} { $X_f = X_f \cup \{x^\prime\}$ } } }
\end{algorithm2e}

\vspace{1cm}

Feeding the paths modified paths $p_1^1,p_2^1,p_3^1$, that are equal to the
normal paths $p_1,p_2,p_3$, and the paths $p_1^2,p_2^2,p_3^2$ to algorithm
\ref{alg:identification}, two models are identified, one for $k=1$ and another for
$k=2$, their state transition diagrams are represented in \Autoref{fig:examplek1,fig:examplek2} respectively. 

\begin{figure}[H]
  \centering \includegraphics[width=\textwidth]{automata/daoct/example.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{State transition diagram for identified model using $k=1$.}
  \label{fig:examplek1}
\end{figure}


\begin{figure}[H]
  \centering \includegraphics[width=\textwidth]{automata/daoct/examplek2.tikz}
  % \includetikzfigure[width=0.5\textwidth]{automata/example/example}
  \caption{State transition diagram for identified model using $k=2$.}
  \label{fig:examplek2}
\end{figure}

As expected, with a greater value of $k$, more states are identified, since the
number of unique vertices increases with $k$.

One thing that can be noted in those state transition diagrams is that the
resulting set
of the path estimation function $\theta$ of each transition is represented
besides the corresponding event of that transition. That is made with the
purpose of showing the ``conditional transitions'' part of the \DAOCT{} model. A
transition is enabled and can occur if and only if all previous transitions are
associated to the same path. To summarise this in mathematical language it is
needed to expand the domain of function $\theta$ to consider sequence of events,
instead of only an event. This new estimation function will be denoted as
$\theta_s : X \times \Sigma^\star \rightarrow 2^R$. And it is defined
recursively as:

\begin{align}
  \theta_s(x,\epsilon)&=R,\nonumber\\
  \theta_s(x,s\sigma)&=
                       \begin{cases}
                         \theta_s(x,s) \cap \theta(x',\sigma),       & \quad \text{where $x^\prime = f(x,s)$, if $f(x,s\sigma)!$ }\\
                         \text{undefined, otherwise.}  &
                       \end{cases}
\end{align}
Where ! denotes \emph{is defined}.

And once this function is defined we can describe the language generated by this
identified model:
\begin{align}
  L(DAOCT)&:=\{s \in \Sigma^\star : f(x_0,s)! \wedge \theta_s(x_0,s)\neq \emptyset \}
\end{align}

From a similar way it is possible to define the language formed by all
subsequences of events of length $n$ generated by the identified model:

\begin{align}
  L_S^n(DAOCT)&:=\{s \in \Sigma^\star : (|s| = n)\left[\exists x_i \in X,f(x_i,s)! \wedge \theta_s(x_i,s)\neq \emptyset \right]\}
\end{align}

In order to calculate the exceeding language $L_{Exc}^{\leq n}$, another
language is presented, $L^{\leq n}(DAOCT)$, since the definition of
$L_{Exc}^{\leq n}$ is $L_{Exc}^{\leq n}=L^{\leq n}(DAOCT)\backslash
L_{Orig}^{\leq n}$.


\begin{align}
  L^{\leq n}(DAOCT)&:=\left( \bigcup_{i=0}^n L_S^i(DAOCT) \right)\cap L(DAOCT)
\end{align}
As we assumed that all sequences of events that have length $n_0+1$ were
observed, then $L_{Orig}^{\leq n_0}\approx L_{Orig}^{\leq n_0}$. If $n\leq n_0$,
then $L_{Orig}^{\leq n}\approx L_{Orig}^{\leq n}$, and $L_{Exc}^{\leq n}=L^{\leq n}(DAOCT)\backslash
L_{Obs}^{\leq n}$, and this formula will be used to calculate $L_{Exc}^{\leq n}$
throughout this work. 
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../monografia.tex"
%%% End:
